{
  "cells": [
    {
      "metadata": {
        "id": "Fb9huVqbUvVu",
        "colab_type": "text",
        "_uuid": "8dd72e6fe72e190b08c3917d81e7d504139a65b0"
      },
      "cell_type": "markdown",
      "source": "**Digits Recognizer Using keras**\n<hr/>\nThis notebook is inspired by Andrew Ng's CNN course from the Deep Learning Specialization track on Coursera and a WiMLDS meetup\n\nI stumbled on the Kaggle Digit Recognizer [Competition](https://https://www.kaggle.com/c/digit-recognizer)  and decided to try it out using the MNIST dataset provided.\n\nits a digit recognizer trained on the MNIST digits dataset. I built it on the Keras API. I initially tested tried it on my CPU, but it took too long to train a single epoch. Got introduced to Google Colab Notebook... (Ended up being a life saver).\n\nIf you will run this notebook, on CPU, i'll recommend you set the epoch to 3. If you have a GPU, you are good to run the entire 20 epochs.\n\nPS: Created the notebook on Google's Colab, so you may see some google packages... You can try it out!"
    },
    {
      "metadata": {
        "id": "22GS9wU61W-3",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "6220c3e7e8f17aaa2cdc0ab6b6aa3614e5338226",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#lets import the required packages\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\n\nimport tensorflow as tf\nfrom keras import Sequential, Input, Model\nfrom keras.utils import to_categorical\nfrom keras.losses import categorical_crossentropy\nfrom keras.layers import  Dense, Dropout, Flatten, Conv2D,MaxPooling2D\nfrom sklearn.metrics import confusion_matrix\nfrom keras.optimizers import Adam, RMSprop,Adadelta, Adagrad\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import Softmax,LeakyReLU,activations\nfrom sklearn.model_selection import train_test_split\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mnRajbHVSsRQ",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "3416a90e7a93e6fdbf13dfc35873664651b6678e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#loading the datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uioWF2Evawyl",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "8136be66b6a04b60b5a62941adfd8b666bd3f704",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#seperate the label into a variable y_train, and drop the column from our training set\ny_train = train['label']\nx_train = train.drop(['label'], axis =1) \nx_test = test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b_2D1GPAZyYN",
        "colab_type": "text",
        "_uuid": "caecc8bc456919f8fdb489c0ccddab5f0947b512"
      },
      "cell_type": "markdown",
      "source": "# Dataset Inspection\nLets inspect the shape of the data"
    },
    {
      "metadata": {
        "id": "TyfZI88CcZDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60676a22-e29c-489c-9362-1ee34c8dd989",
        "trusted": true,
        "_uuid": "922f92442b005178f987c254e1b31ee449322c60",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Lets inspect the shape of the dataset\nprint('Train X  Dimension :',x_train.shape)\nprint('Test Dimension :',x_test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97yS0F0QcwTm",
        "colab_type": "text",
        "_uuid": "e1256caddc6e1ec5f082747a436f6a3874e2edfa"
      },
      "cell_type": "markdown",
      "source": "There are 42K  rows and 785 columns for training, while test has 28K rows and 748 columns."
    },
    {
      "metadata": {
        "id": "1SQ7dkfSagAQ",
        "colab_type": "text",
        "_uuid": "33f5711110a199c6474d1c2e028f3f6b2d04513b"
      },
      "cell_type": "markdown",
      "source": "**Check both datasets for null or missing values** "
    },
    {
      "metadata": {
        "id": "ahxnpclJaWZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0de5e238-e991-46a3-d1eb-8c18fa501674",
        "trusted": true,
        "_uuid": "4f372a5623a72f9d4807b61dbe16dd695588369a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(x_train.isnull().any().describe())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ta7iCt4Xa76C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "87ad6f43-bc4b-4280-e4eb-d90f9fd55dd3",
        "trusted": true,
        "_uuid": "6fe6642c2f6709f059ea70dfd6fc5dbce677fa26",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(x_test.isnull().any().describe()) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBMGCiSlay5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "outputId": "44bea565-6e83-483e-fa57-de517ee54906",
        "trusted": true,
        "_uuid": "4192778454ae8f20267e3a3d649e002ef0e450f1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Are the categories well represented ?\nsns.set(style=\"darkgrid\")\nsns.countplot(y_train)\nplt.xlabel(' Digits')\nplt.ylabel('Count')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1M_EGU5bj2e",
        "colab_type": "text",
        "_uuid": "0b11260ce7a0df309c9c2f1acb8388cf4da59028"
      },
      "cell_type": "markdown",
      "source": "Yes, they are. The categories are well represented"
    },
    {
      "metadata": {
        "id": "xshq7ze7alst",
        "colab_type": "text",
        "_uuid": "6df5244d2ba0144f347f33c4b88a1e238cc545f6"
      },
      "cell_type": "markdown",
      "source": "\n"
    },
    {
      "metadata": {
        "id": "PUZfg35obftO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28b93383-4ce6-498f-9025-62db958fee0d",
        "trusted": true,
        "_uuid": "b31d63c2e03fa2ef4dccf5295626ff7cf6617543",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Check for what categories the label contains\ncategories = y_train.unique()\nprint('Output Categories: ',categories)\nprint('Total number of  Categories: ',len(categories))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fUfuw8QhFkEk",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "a73a7d77ef474f3ea3e6df4f966d51fbc066a7cb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#categories",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vKgAYYAwidpB",
        "colab_type": "text",
        "_uuid": "0ceaad22f5cd670629aedbb63ebff27dd39e5510"
      },
      "cell_type": "markdown",
      "source": "**Fair Enough no problems.. **Dont expect your datasets to be this neat all the  time. Time to treat the data before we can feed it into a CNN"
    },
    {
      "metadata": {
        "id": "jxfu0aFKv2e5",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "232ead85fbc1b35f6ebc9f97f3eaef520d98779a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#x_train = (x_train.iloc[:,1:].values).astype('float32') # all pixel values\n#y_train = y_train.values.astype('int32') # only labels i.e targets digits\n#x_test = x_test.values.astype('float32')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "439HkR8qi_I7",
        "colab_type": "text",
        "_uuid": "7bb3858730d273b1ecf365c9961be971bfcc1dd8"
      },
      "cell_type": "markdown",
      "source": "# Dataset Preparation\nBefore we design the  Convultion Network, its important to treat the dataset. Various steps are involved.\n* Normalization\n* Reshaping\n* Label Encoding\n* Splitting data into Training and Validation sets\n"
    },
    {
      "metadata": {
        "id": "y7Jlk1tcqAJm",
        "colab_type": "text",
        "_uuid": "f5a5f5bf6fa8f06348415f15adf5b936daf52ff0"
      },
      "cell_type": "markdown",
      "source": "## Normalization\nHere we performa grayscale normalization on the data, technically we are centering the data around zero mean and unit variance, mean = 0, variance =1"
    },
    {
      "metadata": {
        "id": "Dgil_eHQi6IS",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "8936ea41ed64fb630df72da45c6ec7f28f829808",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "X_train = x_train/255.0\nX_test = x_test/255.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlzOIsUb2H1r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86f9b0dc-9beb-4f76-bd3b-77ceb591aab8",
        "trusted": true,
        "_uuid": "e1c1cb6600f0e89483d9b474fb60c2a6523951ee",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCe40l3lqqD5",
        "colab_type": "text",
        "_uuid": "1ba1acffff9f537750247b407b3140804c40bd72"
      },
      "cell_type": "markdown",
      "source": "## Reshaping\nHere we reshape the image into a 3 dimension matrices of  28px by 28px by 1"
    },
    {
      "metadata": {
        "id": "SZ50K4dbr_W8",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "c9b5bd5d40b85ef6f7aa99f4a48ab6bc9ce71dc7",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "x_train = X_train.values.reshape(-1,28,28,1)\nx_test = X_test.values.reshape(-1,28,28,1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkmAzh5wsyOk",
        "colab_type": "text",
        "_uuid": "2afe6f6098d9cce36d17eafbe33f4239e0f81483"
      },
      "cell_type": "markdown",
      "source": "## Label Encoding\nA one-hot vector is a vector which is 1 in an single dimension and zeros elsewhere, for instance 6 will be [0,0,0,0,0,0,1,0,0,0]\n"
    },
    {
      "metadata": {
        "id": "ocDwyiqFr1E-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8b8583d-6f33-490d-ac25-8d2a9b189eec",
        "trusted": true,
        "_uuid": "4dae9857c3f7038787d9aa151a17a6092aa9b4a6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_train_enc = to_categorical(y = y_train, num_classes= len(categories))\n# Display the change for category label using one-hot encoding\nprint('Original label:', y_train[25])\nprint('After conversion to one-hot:', y_train_enc[25])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3gZoFPBuYNg",
        "colab_type": "text",
        "_uuid": "189708a6d58357736e7e96bc9e85abdb8781a7cc"
      },
      "cell_type": "markdown",
      "source": "* ### Lets Visulaize some of the images"
    },
    {
      "metadata": {
        "id": "5gOGsabcujNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "0f58ce9e-545e-49d9-dc53-1610a0af8499",
        "trusted": true,
        "_uuid": "c0be3242970183d73dd9352786626ed6e715352a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "for i in range(0, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(x_train[i][:,:,0], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMylHIT07Cx2",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "77df17e4a796a424de2abe709fbfcfee04c65b94",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "seed = 30\nnp.random.seed(seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LF86avh5zau5",
        "colab_type": "text",
        "_uuid": "d774dbeb99f7878a05919f3ac12200b5ad0de03e"
      },
      "cell_type": "markdown",
      "source": "# Spliting Data into Training and Validation Set\nI'll split the training data into two parts; a small percentage - 15% to contain the validation set, on which we would evaluate the model, while the data will be trainined on the remaining 85%"
    },
    {
      "metadata": {
        "id": "Tr3A6Q6J0y1C",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "f7e529a82e1b786287c064295a142066008e73b0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Spliting the Data\ntrain_x, validation_x, train_y,validation_y = train_test_split(x_train,y_train_enc, test_size = 0.15, random_state = seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0aP4UVId7Vfv",
        "colab_type": "text",
        "_uuid": "1d1fe2909ccdb20a639de99212c740b3499fa7a8"
      },
      "cell_type": "markdown",
      "source": "# Model Architecture\nI'll use the [Keras](https://https://keras.io/) Sequential API, where I'll have to create the CNN one step at a time by adding layers. \n\nThe first layer is the Convultional2D layer, which is a set of learnable filters, i want to model to learn,. The first Conv2D latyer will contain 32 filters, the next will conv layer will contain 64 filter,  wile the last Conv2D layer sill have 128 filters.\nInbetween the Conv2D layers there will be be an Activation Layer, \n\nI've chosen the Rectified Linear Unit, this activatinon function adds some non linearity to the model.\n\nAfter the activation layer is a MaxPooling2D Layer, this layer acts a as a downsampling filter, it selects the maximum pixel in a block defined by the filter parameter i specified. It looks at the two neigbhouring pixels and pick the maximum pixel. Other implementations of the of this feature include [Average Pooling](https://keras.io/layers/pooling/#averagepooling2d)  and [GlobalPooling2D](https://keras.io/layers/pooling/#globalmaxpooling2d). This MaxPooling reduces computational cost.\n\nAfter the Pooling Layer is the DropoutLayer, this is used for regularization. It randomly drops some nodes in the layer.\n\nThe Flatten layer converts the features into a single 1D vectors and finally the Dense Layer which is uses the softmax classifier"
    },
    {
      "metadata": {
        "id": "ZTnbBIS5-mHz",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "90d00a686b577b7f17a35c444e273a66182db499",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import keras\nfrom keras import Sequential, Input, Model\nfrom keras.layers import  Dense, Dropout, Flatten, Conv2D,MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import Softmax,LeakyReLU,activations\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam, RMSprop, SGD",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efvt1Ap8-wwX",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "7048667e1e4978f715f77e53f4e016ba6b4e24be",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#some HyperParameters. Feel Free to tune them\nbatch_size = 128\nepochs = 20\nalpha = 0.3\nnum_classes = 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ausc9Y_a-40o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "12eb281c-42e1-4448-a951-7f0b2afff1b7",
        "trusted": true,
        "_uuid": "1f49f22d34b76d32f73edb53fd6b88992d1f6ed4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Model Architecture in Summary is [[Conv2D -> ReLU -> MaxPool2D -> DroupOut]] *2 -> Dense -> ReLU -> Flatten -> Droupout -> Dense -> Out\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='linear', padding='same',input_shape = (28,28,1)))\nmodel.add(LeakyReLU(alpha=alpha))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='same'))\nmodel.add(Dropout(rate = 0.5))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='linear', padding='same'))\nmodel.add(LeakyReLU(alpha=alpha))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='same'))\nmodel.add(Dropout(rate = 0.4))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(LeakyReLU(alpha=alpha))\nmodel.add(Flatten())\n\nmodel.add(Dropout(rate=0.4))\nmodel.add(Dense(len(categories), activation='softmax'))\nmodel.compile(loss=categorical_crossentropy, optimizer=Adagrad(), metrics=['accuracy'])\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hk0-R4yxHtZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "9bb0f4bf-3f6b-46e1-e309-5f1ef39fd79c",
        "trusted": true,
        "_uuid": "4406d3f86bf9358e3382b7d4dae6dd4bb5409c33",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#training the model\nmodel_train = model.fit(x = train_x, y = train_y, batch_size= batch_size, epochs = epochs, validation_data=(validation_x,validation_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7XHnE_QLWEb",
        "colab_type": "text",
        "_uuid": "36d13cfbcfd3fd22e8a80e62d0e1c929bc1d6e92"
      },
      "cell_type": "markdown",
      "source": "Lets inspect the Model if its overfitting"
    },
    {
      "metadata": {
        "id": "qUfA8uVhLQ32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "5ed956f6-1f64-4fba-a612-8b12756af37a",
        "trusted": true,
        "_uuid": "59f14c6b6525ce77fc7240ee8f92ae71e43bc0ca",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#extracting the training history params. this will give some information if its overfitting\ntrain_acc = model_train.history['acc']\ntrain_loss = model_train.history['loss']\nval_acc = model_train.history['val_acc']\nval_loss = model_train.history['val_loss']\n\nep = range(len(train_acc))\nplt.plot(ep, train_acc,  label='Training accuracy', color ='g')\nplt.plot(ep, val_acc, 'b', label='Validation accuracy',color='r')\nplt.title('Training and validation accuracy')\nplt.legend()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "50jEVAToSFbA",
        "colab_type": "text",
        "_uuid": "90f80e225a2b9d1cbdfc3f6ec3481e916c4b154d"
      },
      "cell_type": "markdown",
      "source": "Our Model isnt doing bad afterall. Validation Accuracy is higher than the training accuracy alomst everytime while training. This means the model isnt oferfitting\n\n### Feel free to tune the hperparameters, modify the NN architecture or try different optimizers"
    },
    {
      "metadata": {
        "id": "iSo6R05DgLKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "5f028d29-1cb9-49b1-83b1-55ead484d5fd",
        "trusted": true,
        "_uuid": "4e5e4074257ccadcdad40d456ac8dd5b042dd0b3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#plt.figure()\nplt.plot(ep, train_loss, label='Training loss')\nplt.plot(ep, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1yuXt1vSExt",
        "colab_type": "text",
        "_uuid": "eaccb7e95354b0fd11e45a1b75dd6d50298a7857"
      },
      "cell_type": "markdown",
      "source": "The validation loss is reducing after almost every epoch, this clearly indicates the model isnt doing bad"
    },
    {
      "metadata": {
        "id": "mGRhwiOyi-pc",
        "colab_type": "text",
        "_uuid": "37b74c5738f61dc8bafc17f20b58ac18d06169da"
      },
      "cell_type": "markdown",
      "source": "# Prediction and Confusion Matrix\n\nLets Make predictions from the Model and visualize the confusion matrix"
    },
    {
      "metadata": {
        "id": "PWH81YJ2haYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "9f45c37e-94de-4cd6-9986-07329bee41e0",
        "trusted": true,
        "_uuid": "18bfa8a3c8a2fb3609d2b44ae6f1e4a3c23c33ae",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Lets use our model to predict\ny_pred = model.predict(validation_x,verbose =1)\n\n#Convert predicted category to one hot vectors\ny_pred_class = np.argmax(y_pred, axis =1 )\n\nvalid_y_class = np.argmax(validation_y, axis = 1)\n#lets generate the confusion matrix so we can see how right the predictions are\nconfuse_matrix = confusion_matrix(valid_y_class,y_pred_class)\n\nplt.figure(figsize = (10,10))\nsns.heatmap(confuse_matrix, annot= True, fmt = 'd', cmap = 'YlGnBu', linewidths=.9,linecolor='black')\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P8WaYYrGorJD",
        "colab_type": "text",
        "_uuid": "3b458a30beb77aba3d8f5d31cbaebc7b2d8b83e4"
      },
      "cell_type": "markdown",
      "source": "## Why is our model classifying some values wrongly\n\nPerhaps some visual inspections  will tell us why\n\nClassification report will help us identifying the misclassified digits in more detail. We will be able to observe the model performance and  identify which classes it performed poorly"
    },
    {
      "metadata": {
        "id": "nk8DH0PokmW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f7f02ea6-1eda-4471-b7a5-58a84749cd05",
        "trusted": true,
        "_uuid": "750b95afb88b1a9c0e70d48cba387794a8714ad1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(valid_y_class, y_pred_class, target_names=target_names))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N46wJw5Oueo2",
        "colab_type": "text",
        "_uuid": "e2d2c280f4ddfc05d1342859c5fa4e9390b258ae"
      },
      "cell_type": "markdown",
      "source": "The Model is doing pretty well!"
    },
    {
      "metadata": {
        "id": "jL4znYgJg_-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d1e034bd-06ca-4157-f4c4-2ddbf019833d",
        "trusted": true,
        "_uuid": "61fc4bbed3ee41862c2a1e89c00be8225f3e6378",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "errors = (y_pred_class - valid_y_class != 0)\ny_pred_classes_errors = y_pred_class[errors]\ny_pred_errors = y_pred[errors]\ny_true_errors = valid_y_class[errors]\nx_val_errors = validation_x[errors]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "475e2bd859c5a4aec02f2b7d320269056870f0d5"
      },
      "cell_type": "markdown",
      "source": "The displayerror() function is inspired by [Yassineghouzam](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)"
    },
    {
      "metadata": {
        "id": "ijZIEk2oxHw4",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "f580f934eda139c9fb842ac36cce666e6d9035b3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kO84GMCGylqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "5eef7dfe-874c-48b0-85f0-a39bf9abefa4",
        "trusted": true,
        "_uuid": "28c27826ef50cfadee1a159679419da4c9c1b357",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Probabilities of the wrong predicted numbers\ny_pred_errors_prob = np.max(y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, x_val_errors, y_pred_classes_errors, y_true_errors)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sI1t6MpcyenX",
        "colab_type": "text",
        "_uuid": "42af84e0a0bd9c153e7a764f8672043a24491c0a"
      },
      "cell_type": "markdown",
      "source": "** The erros are obvious afterall..**"
    },
    {
      "metadata": {
        "id": "5IZsAyWazAxl",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "3e51cdaf9e04d88a38bec2781bdec55d3be5f204",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Lets use the model to predict the testset from Kaggle Competition\npredictions = model.predict(x_test)\npredictions = np.argmax(predictions, axis = 1)\npredictions = pd.Series(predictions, name =  'Label')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLSs_b1y8jQe",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "3bbe6da18279ed71f3f76f044eda33092f991ebe",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbQxKnQp--Ey",
        "colab_type": "text",
        "_uuid": "0f227a9da9787ec1046b635ce7e7f8444a36e3ba"
      },
      "cell_type": "markdown",
      "source": "# Training on Entire Competition Training set\nAfter you've evaluated the model, and confim its doing well, you can then proceed to use the competition's training set and predict on the test set."
    },
    {
      "metadata": {
        "id": "YUrS90T080XC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "cc74cd74-7e39-4ca3-d5b8-42c5a06a9021",
        "trusted": true,
        "_uuid": "a7d8a691eef9dfc0c396ef0cf13832d92db71603",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#training the model\nmodel_train_full = model.fit(x = x_train, y = y_train_enc, batch_size= batch_size, epochs = epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "To28vczZBRL8",
        "colab_type": "code",
        "colab": {},
        "trusted": true,
        "_uuid": "17e9fa22acb98c57f27f0c024c46e45151a218ed",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#Lets use the model to predict the testset from Kaggle Competition\npredictions_full = model.predict(x_test)\npredictions_full = np.argmax(predictions_full, axis = 1)\npredictions_full = pd.Series(predictions_full, name =  'Label')\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions_full)+1)),\"Label\": predictions})\nsubmissions.to_csv(\"Submission.csv\", index=False, header=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PseQpX7WBiz1",
        "colab_type": "text",
        "_uuid": "ba5e830a2811341bca9a286edbd9ee687389396d"
      },
      "cell_type": "markdown",
      "source": "#### if you find this note useful, some upvotes will be appreciated.. Feel free to criticize the notebook. \n\nPS: This is my first kernel here... "
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of Digit Recognizer Playground.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}